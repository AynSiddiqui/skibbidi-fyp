[MODEL_CONFIG]
rmsp_alpha = 0.99
rmsp_epsilon = 1e-5
max_grad_norm = 40
gamma = 0.99
lr_init = 5e-4
lr_decay = constant
; Epsilon scheduling parameters for exploration in DQN
epsilon_init = 1.0
epsilon_decay = linear
epsilon_min = 0.1
; Network architecture parameters for the DeepQPolicy
num_h = 64
num_fc = 128
batch_size = 5
reward_norm = 100.0
reward_clip = 2.0

[TRAIN_CONFIG]
total_step = 1e5
test_interval = 2e4
log_interval = 1e3

[ENV_CONFIG]
clip_wave = 2.0
clip_wait = 2.0
control_interval_sec = 5
; agent options: greedy, iqll, iqld, ia2c, ma2c, a2c, dqn
agent = dqn
coop_gamma = 0.9
data_path = ./worli/data/
episode_length_sec = 3600
norm_wave = 5.0
norm_wait = 30.0
coef_wait = 0.2
flow_rate = 325
objective = hybrid
scenario = worli
seed = 42
test_seeds = 10000,20000,30000
yellow_interval_sec = 2
